<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Evolution and Vision</title>
<meta name="author" content="(William F. Broderick)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme"/>

<link rel="stylesheet" href="custom.css"/>
<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css"/>
<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<meta name="description" content="theo neuro JC evolution">
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">Evolution and Vision</h1><h2 class="author">William F. Broderick</h2><h2 class="date">2017-04-17</h2><p class="date"></p>
</section>
<aside class="notes">
<p>
this is going to be kind of rambly, because there are a couple of
different points I want to talk about and we could probably spend time
discussing each of them
</p>

<p>
this presentation is also going to partly be a collection of neat
facts
</p>

</aside>

<section>
<section id="slide-orgeadfea1">
<h2 id="orgeadfea1">Overview</h2>
<p>
Why is rodent visual system so different from human and what does
that mean for vision?
</p>

<ul>
<li class="fragment appear">Eyes</li>
<li class="fragment appear">Of mice and men</li>
<li class="fragment appear">Why maps?</li>

</ul>

<aside class="notes">
<p>
my interest in this got started when we were taught that rodents have
neither foveas nor orderly orientation columns in V1. rodents can
still do orientation discrimination 2AFC-type tasks, so then what's
the point of those maps?
</p>

<p>
and why <i>not</i> have foveation? To me, it makes sense to have fovea
because of limitation: can only get so many axons through the optic
disk, we take super high resolution in one point instead of
kind-of-high everywhere.
</p>

<p>
before I get started, does anyone have any ideas?
</p>

<p>
This will kind of be about evolution, but more about ethology,
comparing visual systems of different animals. Unfortunately, most of
what we know is about structure of eyes (and so the optics), not on
the functional properties. I think relatively few species have had
their V1 characterized. 
</p>

<p>
I also don't think I have a single equation in this presentation, so
that's new for us
</p>

<p>
things we'll talk about: (make all appear)
</p>

</aside>

</section>
</section>
<section>
<section id="slide-orgf3da835">
<h2 id="orgf3da835">What's the point of vision?</h2>
<p>
"If the question is how the brain leads to behavior, we are first
asking why is the brain performing this behavior and then asking how
is it doing it" &#x2013; Krakauer et al, 2017
</p>

<aside class="notes">
<p>
so what's the point of vision?
</p>

<p>
as Roozbeh argued, brains are for motion, not vision. Vision is to
facilitate motion / tasks
</p>

<p>
Relevant to Krakauer2017: "if the question is how the brain leads to
behavior, we are first asking why is the brain performing this
behavior and then asking how is it doing it".
</p>

<p>
For us, if we want to know what eyes are doing and how they're
facilitating behavior, we should know what behaviors they're
facilitating and how they're solving relevant tasks
</p>

<p>
so first I'm going to talk a bit about eyes and what they're used for,
as well as how they differ across species in ways that I think are
interesting.
</p>

</aside>

</section>
<section id="slide-org1301640">
<h3 id="org1301640">Light-controlled behaviors</h3>
<ol>
<li>Behaviors controlled by ambient light (circadian rhythms)</li>
<li>Behaviors based on directional light (phototaxis)</li>
<li>Tasks requiring low spatial resolution (object avoidance,
orientation to sun)</li>
<li>Tasks requiring high spatial resolution (detection and pursuit
of prey, recognition of individuals)</li>

</ol>

<aside class="notes">
<p>
four types of light-controlled behaviors and four types of
light-sensing organs
</p>

</aside>

</section>
<section id="slide-orge946b52">
<h3 id="orge946b52">Light-sensitive organs</h3>

<div class="figure">
<p><img src="../images/Land2010-Fig1.5.jpg" alt="Land2010-Fig1.5.jpg" width="90%" height="90%" />
</p>
</div>

<aside class="notes">
<p>
this is a reminder that these organs are very well suited to the tasks
described above. they are sufficient. the point of evolution is not to
produce humans
</p>

<ul>
<li>unshielded photoreceptors and signalling mechanism</li>
<li>screening pigment so amount of light received changes with direction</li>
<li>resolution of 5 to 30 degrees, stacking of photoreceptors (in order
to get enough photons)</li>
<li>resolution &lt;2 degrees, lens or other focusing arrangement, eye with
focusing optics</li>

</ul>

</aside>

</section>
<section id="slide-orgb621786">
<h3 id="orgb621786">Parallel evolutions of eyes</h3>

<div class="figure">
<p><img src="../images/Land2010-Fig1.9.jpg" alt="Land2010-Fig1.9.jpg" width="50%" height="50%" />
</p>
</div>

<aside class="notes">
<p>
four evolutions of eyes
</p>

<p>
all of these evolved to solve that fourth class of problems, but do so
differently
</p>

<p>
going to talk about land vertebrates, which all have eyes of one
class. differences are relatively small,
</p>

</aside>

</section>
</section>
<section>
<section id="slide-org0e95a19">
<h2 id="org0e95a19">Eye properties</h2>
<ul>
<li>Resolution: how finely the optical environment is sampled</li>
<li>Sensitivity: how many photos your receptors receive</li>

</ul>

<p class="fragment (appear)">
To make either one better: increase eye size
</p>

<aside class="notes">
<p>
two properties of eye: resolution and sensitivity
</p>

<ul>
<li>resolution: sampling density of retinal receptors and quality of
optical image. photoreceptors can't be smaller than 1 to 2 microns
because of waveguide effects, so after that you can only increase
resolution by increasing focal length (fig 3.2). for image quality,
bigger apertures have smaller diffraction effects.</li>
<li>sensitivity: get as many photons to receptors as possible, so large
aperture and receptors (which compromises resolution). once you've
maximized aperture diameter for given focal length, have to increase
eye size</li>

</ul>

</aside>
</section>
<section id="slide-orgbf5ece6">
<h3 id="orgbf5ece6">OWLS</h3>

<div class="figure">
<p><img src="../images/superb-owl.jpg" alt="superb-owl.jpg" width="80%" height="80%" />
</p>
</div>

<aside class="notes">
<p>
Owls are a good example of this. because they need to see both well in
the dark and with good resolution, they have really really big eyes
</p>

</aside>
</section>
<section id="slide-org1e63ee6">
<h3 id="org1e63ee6">OWLS</h3>

<div class="figure">
<p><img src="../images/owl-eyes.jpg" alt="owl-eyes.jpg" />
</p>
</div>
<aside class="notes">
<p>
so big in fact, that they're no longer spherical. they're slightly
tubular, deformed so they can be as large as possible and still fit in
the head 
</p>

<p>
so even though they have a full set of eye muscles, they can't move
eyes more than a few degrees around any axis
</p>

</aside>

</section>
<section id="slide-org0e39703">
<h3 id="org0e39703">Pupils and light levels</h3>

<div class="figure">
<p><img src="../images/Land2010-Fig5.11.jpg" alt="Land2010-Fig5.11.jpg" width="70%" height="70%" />
</p>
</div>

<aside class="notes">
<p>
pupils and light levels
</p>

<p>
pupils change in size rapidly in response to changes in illumination
of retina (whereas fish pupils may take minutes to open and close, if
they do so at all, and are often activated directly by light, not
neurally). circular pupils cannot close beyond a certain limit, while
slit pupils can close much farther (useful because very sensitive
photopigments, like those nocturnal animals have, need to be
protected from daylight; for example, human pupil size change is <b>4</b>
times, cat's is <b>135-fold</b>, fig 5.11). geckos' pupil size can cause
reduction of light by a <b>1000-fold</b>
</p>

</aside>

</section>
<section id="slide-orgd83cb9f">
<h3 id="orgd83cb9f">Binocular vision</h3>

<div class="figure">
<p><img src="../images/Land2010-Fig5.13.jpg" alt="Land2010-Fig5.13.jpg" />
</p>
</div>

<aside class="notes">
<p>
how eyes are placed on the head reflects what they need vision for
</p>

<p>
most predatory species have more overlap and thus larger rear-facing
blind spot. 
</p>

<p>
for primates, "provides basis for stereoscopic vision &#x2026; of great
value when looking for an manipulating objects within a range of up
to a few meters". 
</p>

<p>
prey have laterally directed eyes, giving them almost 360 degrees of
view
</p>

</aside>

</section>
<section id="slide-org39a5722">
<h3 id="org39a5722">Ganglion cell distribution</h3>

<div class="figure">
<p><img src="../images/Land2010-Fig5.12.jpg" alt="Land2010-Fig5.12.jpg" width="70%" height="70%" />
</p>
</div>

<aside class="notes">
<p>
so this gets a little bit at function. this is the ganglion cell
distribution, which presumably reflects acuity
</p>

<p>
many (cheetahs, rabbits, ungulates) whose life activity dominated by
horizon have a <b>visual streak</b>, with ganglion cells concentrated on
horizontal strip. 
</p>

<p>
those with more 3d environment, like forest, have more uniform retina
or "area centralis". 
</p>

<p>
for humanprimates, this is about the 1 degree central spot, fovea
centralis, where we have about one ganglion cell per cone (\(150*10^3\)
per square mm, vs \(6*10^3\) in area centralis of the rat).
</p>

<p>
birds often have two foveas, one looking out laterally and the other,
siautated at the rear of the retina imaging region of bill where bird
pecks at food (like pigeon in figure)
</p>

<p>
ganglion cell distribution
</p>

</aside>

</section>
<section id="slide-org3478625">
<h3 id="org3478625">Hawk acuity</h3>

<div class="figure">
<p><img src="../images/hawk-fovea.jpeg" alt="hawk-fovea.jpeg" />
</p>
</div>

<aside class="notes">
<p>
this image shows the two fovea: deep and shallow in the short tailed
hawk (from
<a href="http://iovs.arvojournals.org/article.aspx?articleid=2126809">http://iovs.arvojournals.org/article.aspx?articleid=2126809</a>), notice
the pits
</p>

<p>
hawks can resolve 160 cycles / degree (humans can do about 60 cycles
per degree) in bright light. given that our eyes are about the same
size, how is this possible?
</p>
<ul>
<li>daylight pupil is wider (6mm vs 2mm)</li>
<li>foveal receptors are narrower (2 \(\mu m\) between centers, compared
to between 2.5 and 3)</li>
<li>foveal pit increases effective focal length of the eye (fig 5.12),
acting as modest telephoto system, gives 1.45x magnification</li>

</ul>

<p>
most of these are really just about physical differences in the eye,
this is the closest connection to functional differences
</p>

</aside>

</section>
</section>
<section>
<section id="slide-org9fe6657">
<h2 id="org9fe6657">How similar is mouse vision to primate vision?</h2>

<div class="figure">
<p><img src="../images/Marshel2011-Fig1.png" alt="Marshel2011-Fig1.png" />
</p>
</div>

<aside class="notes">
<p>
how similar are mice and primate vision?
</p>

<p>
mice have retinotopic maps, preferred spatial frequencies and
orientations in V1 and higher order visual areas. so that's nice
</p>

<p>
I don't understand the figures that show that, but they're in the
paper
</p>

</aside>

</section>
<section id="slide-org1ec4c81">
<h3 id="org1ec4c81">Ventral visual stream?</h3>
<p>
Receptive field size
</p>


<div class="figure">
<p><img src="../images/RF-sizes.png" alt="RF-sizes.png" />
</p>
</div>

<aside class="notes">
<p>
evidence for sequence of ventral-visual-stream like in mouse visual
areas
</p>

<p>
RF size increases (figure <a class='org-ref-reference' href="#Freeman2011b">Freeman2011b</a> fig1,
<a class='org-ref-reference' href="#Wandell2015-comput-neuroim">Wandell2015-comput-neuroim</a> fig1) as you go up the
stream. here's comparison across species
</p>

</aside>

</section>
<section id="slide-org26abced">
<h3 id="org26abced">Decoding object identity from mice</h3>

<div class="figure">
<p><img src="../images/Tafazoli2017-Fig8.png" alt="Tafazoli2017-Fig8.png" width="50%" height="50%" />
</p>
</div>


<aside class="notes">
<p>
decoding figures: compare <a class='org-ref-reference' href="#Tafazoli2017-emerg-trans">Tafazoli2017-emerg-trans</a> fig8 with
<a class='org-ref-reference' href="#Rust2010-selec-toler">Rust2010-selec-toler</a> fig7c and 8b
</p>

<p>
and they look similar
</p>

</aside>

</section>
<section id="slide-org245560d">
<h3 id="org245560d">Decoding object identity from macaques</h3>

<div class="figure">
<p><img src="../images/Rust2010-Figs78.png" alt="Rust2010-Figs78.png" width="50%" height="50%" />
</p>
</div>

<aside class="notes">
<p>
so that's pretty comforting
</p>

</aside>

</section>
</section>
<section>
<section id="slide-orge3ffefc">
<h2 id="orge3ffefc">Mouse V1 orientation preferences inherited from LGN</h2>

<div class="figure">
<p><object type="image/svg+xml" data="../images/Scholl2013-Fig4.svg" class="org-svg">
Sorry, your browser does not support SVG.</object>
</p>
</div>

<aside class="notes">
<p>
but mouse orientation selectivity comes from LGN so how even basic
information is handled is different across these species
</p>

<p>
(grey is during cortical inactivation, open blue from extracellular
single-unit recordings instead of single-unit) &#x2013; distributions for
mouse LGN and V1 are similar, whereas cat shows enhancement of
selectivity
</p>

</aside>

</section>
<section id="slide-org88f0b65">
<h3 id="org88f0b65">Cross-species differences</h3>

<div class="figure">
<p><img src="../images/Notes-animal-orientation.png" alt="Notes-animal-orientation.png" />
</p>
</div>

<aside class="notes">
<p>
and we have these differences <a class='org-ref-reference' href="#Scholl2013-emerg-orien">Scholl2013-emerg-orien</a> fig5 so what
are the functional results of these? why have them?
</p>

</aside>

</section>
</section>
<section>
<section id="slide-org4f2d5b8">
<h2 id="org4f2d5b8">WHY MAPS?</h2>
<p>
Minimizes wiring cost
</p>


<div class="figure">
<p><img src="../images/Chklovskii2004-Fig10.png" alt="Chklovskii2004-Fig10.png" class="fragment (appear)" />
</p>
</div>

<aside class="notes">
<p>
why maps? anatomical reason and possibly functional ones, what do
people think?
</p>

<p>
<a class='org-ref-reference' href="#Chklovskii2004-maps-in">Chklovskii2004-maps-in</a>
</p>
<ul>
<li>maps probably come minimizing wiring cost</li>
<li>basically, function inherited from connectivity, and
connecitivty + wiring constrain gives rise to maps</li>
<li>with a wiring cost penalty, you get different maps based on how
cells connect to each other</li>
<li>doesn't answer question of why you'd have different functional
layouts in different animals or why one would be preferred over
the other (retinotopy easy to argue for)</li>

</ul>

<p>
<a class='org-ref-reference' href="#Nauhaus2014-build-maps">Nauhaus2014-build-maps</a>:
</p>
<ul>
<li>well-arranged maps make sampling different portions of the
stimulus space much easier and, if you have two orthogonal ones
at the same time, it's easy to get all possible permutations of
the properties</li>
<li>with maps, sampling different portions of the it will yield
different response distributions, because there's structure and not
"white noise"</li>

</ul>

</aside>
</section>
</section>
</div>
</div>
<p> Created by WFB. </p>
<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: 'c',
rollingLinks: false,
keyboard: true,
overview: true,
width: 1200,
height: 800,
margin: 0.10,
minScale: 0.50,
maxScale: 2.50,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'default',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
 { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
});
</script>
</body>
</html>
